{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2376b625-726e-4262-8c05-28783ea4223a",
   "metadata": {},
   "source": [
    "# Exporting and Deploying with Torschscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f26cc60-d518-4974-8ac1-e12d310a8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "import logging\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
    "from detectron2.checkpoint import DetectionCheckpointer, PeriodicCheckpointer\n",
    "from detectron2.utils.events import EventStorage\n",
    "from detectron2.modeling import build_model\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.engine import default_argument_parser, default_setup, default_writers, launch\n",
    "from detectron2.data import (\n",
    "    MetadataCatalog,\n",
    "    build_detection_test_loader,\n",
    "    build_detection_train_loader,\n",
    ")\n",
    "from detectron2.evaluation import (\n",
    "    CityscapesInstanceEvaluator,\n",
    "    CityscapesSemSegEvaluator,\n",
    "    COCOEvaluator,\n",
    "    COCOPanopticEvaluator,\n",
    "    DatasetEvaluators,\n",
    "    LVISEvaluator,\n",
    "    PascalVOCDetectionEvaluator,\n",
    "    SemSegEvaluator,\n",
    "    inference_on_dataset,\n",
    "    print_csv_format,\n",
    ")\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c202a63-fd22-4393-b213-06711980caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: remove this stupidness.\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1099140f-ec15-408f-be18-abd96861bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in urban-small-2 to coco-segmentation:: 100%|█| 42460/42460 [00:07<00:00, 5727."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to urban-small-2 in coco-segmentation:: 100%|█| 602/602 [00:00<00:00, 3055.13it/\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"gOwZbHTcuBdgjBYxl7Nk\")\n",
    "project = rf.workspace(\"sih-daaio\").project(\"urban-small\")\n",
    "dataset = project.version(2).download(\"coco-segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "080ef546-5b2b-4323-af87-d2d3b2f0999d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'urban-small_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murban-small-2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_coco_instances\n\u001b[0;32m----> 5\u001b[0m \u001b[43mregister_coco_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/train/_annotations.coco.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/train/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m register_coco_instances(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_val\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/valid/_annotations.coco.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/valid/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m register_coco_instances(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_test\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/_annotations.coco.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/data/datasets/coco.py:500\u001b[0m, in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[1;32m    504\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    505\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[1;32m    506\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/data/catalog.py:37\u001b[0m, in \u001b[0;36m_DatasetCatalog.register\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    func (callable): a callable which takes no arguments and returns a list of dicts.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        It must return the same results if called multiple times.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must register a function with `DatasetCatalog.register`!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m[name] \u001b[38;5;241m=\u001b[39m func\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'urban-small_train' is already registered!"
     ]
    }
   ],
   "source": [
    "dataset_name = \"urban-small\"\n",
    "dataset_folder = \"urban-small-2\"\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(f\"{dataset_name}_train\", {}, f\"./{dataset_folder}/train/_annotations.coco.json\", f\"./{dataset_folder}/train/\")\n",
    "register_coco_instances(f\"{dataset_name}_val\", {}, f\"./{dataset_folder}/valid/_annotations.coco.json\", f\"./{dataset_folder}/valid/\")\n",
    "register_coco_instances(f\"{dataset_name}_test\", {}, f\"./{dataset_folder}/test/_annotations.coco.json\", f\"./{dataset_folder}/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b2b9a-221b-43c5-ac03-6d5514a946d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "716e87c5-e63b-40d3-a24c-0e6c27e4fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"weights/buildings_poc_cfg.yml\"\n",
    "model_weights = \"weights/model_final.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "796cdee9-e391-4520-a000-bec8ce5477e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/05 09:01:17 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from weights/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (256, 256, 3, 3) in the checkpoint but (1024, 1024, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (256,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (15, 1024, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (60, 1024, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (81, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (320, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mbackbone.res2.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.stem.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.stem.conv1.weight\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv1.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv2.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv3.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv1.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv2.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv3.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv1.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv2.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv3.weight\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_lateral3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_lateral4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_lateral5.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output5.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.stem.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.stem.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.box_head.fc1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.box_head.fc2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.deconv.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(yaml_file)\n",
    "cfg.MODEL.WEIGHTS = model_weights\n",
    "cfg.DATASETS.TRAIN = (f\"{dataset_name}_train\",)\n",
    "cfg.DATASETS.TEST = (f\"{dataset_name}_test\",)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n",
    "cfg.MODEL.DEVICE = \"cpu\" \n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7f85f8e-9dbd-4b44-af7c-f074ecb3f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cfg.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3991a92-80b0-4fb8-b38d-699a929327ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/04 20:37:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[10/04 20:37:21 d2.data.datasets.coco]: \u001b[0mLoaded 18 images in COCO format from ./urban-small-2/test/_annotations.coco.json\n",
      "\u001b[32m[10/04 20:37:21 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|   buildings   | 0            | Commercial-.. | 52           | Community Use | 0            |\n",
      "| Industrial-.. | 48           |   Mixed Use   | 23           | Recreationa.. | 0            |\n",
      "|  Residential  | 169          | Transport-I.. | 0            |               |              |\n",
      "|     total     | 292          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[10/04 20:37:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/04 20:37:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/04 20:37:21 d2.data.common]: \u001b[0mSerializing 18 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/04 20:37:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n"
     ]
    }
   ],
   "source": [
    "data_loader = build_detection_test_loader(cfg, cfg.DATASETS.TEST[0])\n",
    "first_batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305baec-de22-4cf9-986d-cd1ec3a8ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = \"weights/buildings_poc_cfg.yml\"\n",
    "model_weights = \"weights/model_final.pth\"\n",
    "./build/torchscript_mask_rcnn output/model.ts input.jpg tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5c04cf5-6eb1-491b-8445-77e11b796b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48898.84s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/05 09:10:15 detectron2]: \u001b[0mCommand line arguments: Namespace(format='torchscript', export_method='tracing', config_file='weights/buildings_poc_cfg.yml', sample_image='demo_data/image1.png', run_eval=False, output='./output', opts=['MODEL.WEIGHTS', 'weights/model_final.pth', 'MODEL.DEVICE', 'cpu'])\n",
      "[W init.cpp:836] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 1) (function operator())\n",
      "\u001b[32m[10/05 09:10:15 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from weights/model_final.pth ...\n",
      "Skip loading parameter 'proposal_generator.rpn_head.conv.weight' to the model due to incompatible shapes: (256, 256, 3, 3) in the checkpoint but (1024, 1024, 3, 3) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.conv.bias' to the model due to incompatible shapes: (256,) in the checkpoint but (1024,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (15, 1024, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (60, 1024, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (81, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (320, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mbackbone.res2.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.1.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res2.2.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.1.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.2.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res3.3.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.1.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.2.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.3.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.4.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv2.weight\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.res4.5.conv3.weight\u001b[0m\n",
      "\u001b[34mbackbone.stem.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.stem.conv1.weight\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv1.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv2.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.conv3.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv1.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv2.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.1.conv3.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv1.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv2.weight\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.res5.2.conv3.weight\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_lateral3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_lateral4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_lateral5.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.fpn_output5.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.stem.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.stem.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res2.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res3.3.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.3.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.4.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.5.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.6.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.7.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.8.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.9.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.10.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.11.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.12.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.13.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.14.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.15.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.16.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.17.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.18.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.19.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.20.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.21.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res4.22.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.shortcut.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.shortcut.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.0.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.1.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv1.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv2.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.bottom_up.res5.2.conv3.norm.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.box_head.fc1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.box_head.fc2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.deconv.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/image_list.py:85: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert t.shape[:-2] == tensors[0].shape[:-2], t.shape\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor.numel() == 0:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor.numel() == 0:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/modeling/proposal_generator/proposal_utils.py:106: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not valid_mask.all():\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  h, w = box_size\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.shape[-1] == 4\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/layers/roi_align.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert rois.dim() == 2 and rois.size(1) == 5\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not valid_mask.all():\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor.numel() == 0:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  h, w = box_size\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_bbox_reg_classes == 1:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.shape[-1] == 4\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/image_list.py:85: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert t.shape[:-2] == tensors[0].shape[:-2], t.shape\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor.numel() == 0:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor.numel() == 0:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/modeling/proposal_generator/proposal_utils.py:106: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not valid_mask.all():\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  h, w = box_size\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.shape[-1] == 4\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/torch/__init__.py:1209: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/layers/roi_align.py:55: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert rois.dim() == 2 and rois.size(1) == 5\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not valid_mask.all():\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor.numel() == 0:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert tensor.dim() == 2 and tensor.size(-1) == 4, tensor.size()\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:191: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert torch.isfinite(self.tensor).all(), \"Box tensor contains infinite or NaN!\"\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/structures/boxes.py:192: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  h, w = box_size\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:155: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_bbox_reg_classes == 1:\n",
      "/Users/henrylydecker/opt/anaconda3/envs/aerial-dev/lib/python3.9/site-packages/detectron2/layers/nms.py:15: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert boxes.shape[-1] == 4\n",
      "\u001b[32m[10/05 09:10:25 detectron2]: \u001b[0mInputs schema: TupleSchema(schemas=[ListSchema(schemas=[DictSchema(schemas=[IdentitySchema()], sizes=[1], keys=['image'])], sizes=[1])], sizes=[1])\n",
      "\u001b[32m[10/05 09:10:25 detectron2]: \u001b[0mOutputs schema: ListSchema(schemas=[DictSchema(schemas=[InstancesSchema(schemas=[TensorWrapSchema(class_name='detectron2.structures.Boxes'), IdentitySchema(), IdentitySchema()], sizes=[1, 1, 1], keys=['pred_boxes', 'pred_classes', 'scores'])], sizes=[4], keys=['instances'])], sizes=[4])\n",
      "\u001b[32m[10/05 09:10:25 detectron2]: \u001b[0mSuccess.\n"
     ]
    }
   ],
   "source": [
    "!detectron2/tools/deploy/export_model.py --config-file weights/buildings_poc_cfg.yml \\\n",
    "    --output ./output --export-method tracing --sample-image demo_data/image1.png --format torchscript \\\n",
    "    MODEL.WEIGHTS weights/model_final.pth \\\n",
    "    MODEL.DEVICE cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2798a27-430a-4c7f-86d2-eec603f5131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49215.03s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: permission denied: scripts/benchmark.cpp\n"
     ]
    }
   ],
   "source": [
    "!scripts/benchmark.cpp output/model.ts demo_data/image1.png tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278bad1f-8ff8-43f8-9e58-ff7250801129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, inputs):\n",
    "    # use do_postprocess=False so it returns ROI mask\n",
    "    inst = model.inference(inputs, do_postprocess=False)[0]\n",
    "    return [{\"instances\": inst}]\n",
    "\n",
    "isinstance(image, np.ndarray) == True\n",
    "image_tensor = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "wrapper= TracingAdapter(predictor, inputs=[{\"image\": image_tensor}], inference_func=inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
